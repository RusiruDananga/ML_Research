{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import ollama\n",
    "from langchain_ollama import OllamaLLM\n",
    "import ast\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/fine_tuning_util.ipynb\n",
    "%run ../utils/save_and_load_util.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv(\"eda_law_cases.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking Text for Training & Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tokenizer\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")  # Using OpenAI's tokenizer\n",
    "max_chunk_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1833/1910 [00:48<00:01, 51.40file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file sc_hc_la_89_2022.pdf due to invalid text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1910/1910 [00:50<00:00, 37.70file/s, remaining=0.00s]\n"
     ]
    }
   ],
   "source": [
    "chunked_data = []\n",
    "total_files = len(df)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with tqdm(total=total_files, desc=\"Chunking Progress\", unit=\"file\") as pbar:\n",
    "    for _, row in df.iterrows():\n",
    "        file_name = row[\"file_name\"]\n",
    "        \n",
    "        # Ensure 'text' is a valid string\n",
    "        text = row[\"text\"]\n",
    "        if isinstance(text, str):  # Proceed only if text is a string\n",
    "            chunks = chunk_text(text)\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                chunked_data.append({\"file_name\": file_name, \"chunk_id\": i, \"text\": chunk})\n",
    "        else:\n",
    "            print(f\"Skipping file {file_name} due to invalid text.\")\n",
    "        \n",
    "        pbar.update(1)\n",
    "    \n",
    "    # Calculate time left and show it dynamically\n",
    "    elapsed_time = time.time() - start_time\n",
    "    remaining_time = (elapsed_time / pbar.n) * (total_files - pbar.n)\n",
    "    pbar.set_postfix(remaining=f\"{remaining_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "chunked_df = pd.DataFrame(chunked_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the chunked data\n",
    "chunked_df.to_csv(\"chunked_law_cases.csv\", index=False)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_df = pd.read_csv(\"chunked_law_cases.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FAISS index\n",
    "d = 384\n",
    "index = faiss.IndexFlatL2(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings:   3%|â–Ž         | 896/30646 [01:20<44:51, 11.05chunk/s] "
     ]
    }
   ],
   "source": [
    "chunked_data_with_embeddings = []\n",
    "total_chunks = len(chunked_df)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with tqdm(total=total_chunks, desc=\"Generating Embeddings\", unit=\"chunk\") as pbar:\n",
    "    batch_size = 32  # Adjust the batch size based on available memory\n",
    "\n",
    "    for i in range(0, total_chunks, batch_size):\n",
    "        batch_texts = chunked_df[\"text\"].iloc[i:i + batch_size].tolist()\n",
    "        embeddings = generate_embeddings(batch_texts)\n",
    "\n",
    "        # Add embeddings to the dataframe\n",
    "        for j, emb in enumerate(embeddings):\n",
    "            chunked_data_with_embeddings.append({\n",
    "                \"file_name\": chunked_df[\"file_name\"].iloc[i + j],\n",
    "                \"chunk_id\": chunked_df[\"chunk_id\"].iloc[i + j],\n",
    "                \"text\": chunked_df[\"text\"].iloc[i + j],\n",
    "                \"embedding\": emb.cpu().numpy()\n",
    "            })\n",
    "        \n",
    "        pbar.update(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the chunked data with embeddings to a DataFrame\n",
    "embedding_df = pd.DataFrame(chunked_data_with_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the embeddings to disk\n",
    "embedding_df.to_csv(\"law_cases_with_embeddings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating FAISS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the chunked data with embeddings\n",
    "embedding_df = pd.read_csv(\"law_cases_with_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string embeddings back to NumPy arrays\n",
    "def parse_embedding(embedding_str):\n",
    "    try:\n",
    "        return np.array(ast.literal_eval(embedding_str), dtype=np.float32)\n",
    "    except:\n",
    "        return np.zeros(384, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_df[\"embedding\"] = embedding_df[\"embedding\"].apply(parse_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert embeddings to a 2D NumPy array\n",
    "embeddings_matrix = np.vstack(embedding_df[\"embedding\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the FAISS index (L2 Normalized for cosine similarity search)\n",
    "embedding_dim = embeddings_matrix.shape[1]  # Get the embedding dimension\n",
    "index = faiss.IndexFlatL2(embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add embeddings to FAISS index\n",
    "index.add(embeddings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save FAISS index\n",
    "faiss.write_index(index, \"law_cases_index.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metadata (file names & chunk IDs) for retrieval\n",
    "metadata = embedding_df[[\"file_name\", \"chunk_id\", \"text\"]].to_dict(orient=\"records\")\n",
    "with open(\"faiss_metadata.pkl\", \"wb\") as f:\n",
    "    pickle.dump(metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FAISS index\n",
    "index = faiss.read_index(\"law_cases_index.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata (file names & text chunks)\n",
    "with open(\"faiss_metadata.pkl\", \"rb\") as f:\n",
    "    metadata = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the embedding model\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Same model used before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model=\"llama3.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_cases(query, top_k=5):\n",
    "    # Convert query into an embedding\n",
    "    query_embedding = embedding_model.encode([query])\n",
    "    query_embedding = np.array(query_embedding, dtype=np.float32)  \n",
    "\n",
    "    # Search FAISS for top 10 matches (to get diversity)\n",
    "    distances, indices = index.search(query_embedding, top_k * 3)  \n",
    "\n",
    "    # Keep track of unique documents\n",
    "    unique_cases = {}\n",
    "    \n",
    "    for i in range(len(indices[0])):\n",
    "        idx = indices[0][i]\n",
    "        if idx < len(metadata):  # Ensure index is valid\n",
    "            case = metadata[idx]\n",
    "            file_name = case[\"file_name\"]\n",
    "            \n",
    "            if file_name not in unique_cases:  # Add only if not already included\n",
    "                unique_cases[file_name] = case\n",
    "\n",
    "            if len(unique_cases) == top_k:  # Stop when we have top_k unique documents\n",
    "                break\n",
    "\n",
    "    return list(unique_cases.values())  # Return only unique cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response_with_llama(query):\n",
    "    \"\"\"\n",
    "    Given a legal query, retrieve relevant law cases and generate a response using Llama 3.1.\n",
    "    \"\"\"\n",
    "    # Retrieve relevant legal cases\n",
    "    relevant_cases = retrieve_relevant_cases(query)\n",
    "\n",
    "    # Combine case texts\n",
    "    case_texts = \"\\n\\n\".join([f\"Case {i+1}: {case['text']}\" for i, case in enumerate(relevant_cases)])\n",
    "\n",
    "    # Construct Llama 3.1 prompt\n",
    "    prompt = f\"\"\"\n",
    "    You are a legal AI assistant. Answer the query based on the following legal cases:\n",
    "\n",
    "    {case_texts}\n",
    "\n",
    "    Query: {query}\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    # Get response from Llama 3.1\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    return response, relevant_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "user_query = \"What are the legal rights of a tenant in a lease agreement dispute?\"\n",
    "response, matched_cases = generate_response_with_llama(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”· AI Legal Assistant Response:\n",
      "\n",
      "Based on general principles of law and the cases provided, I'll address the query. Please note that specific provisions may vary depending on jurisdiction (in this case, Sri Lanka).\n",
      "\n",
      "In general, when it comes to a lease agreement dispute, the rights of a tenant can be summarized as follows:\n",
      "\n",
      "1. **Right to Quiet Possession**: The tenant has the right to peaceful enjoyment of the property during the tenancy period. This means they should not be disturbed or evicted without proper notice and due process.\n",
      "2. **Right to Repairs and Maintenance**: The landlord is responsible for maintaining the property in a habitable condition. If repairs are necessary, the tenant can request the landlord to take action.\n",
      "3. **Right to Receive Rent Payments**: The tenant has the right to receive rent payments as agreed upon in the lease agreement. However, if there's a dispute over rent or late payment fees, the tenant may seek mediation or legal recourse.\n",
      "4. **Right to Terminate Lease**: If the landlord breaches the terms of the lease (e.g., fails to provide essential services), the tenant can terminate the lease without penalty.\n",
      "\n",
      "In Case 1 (SC Application Special Vs. [Expulsion] No. 01/2009), the petitioner, Ameer Ali Shihabdeen, was a member of the Sri Lanka Muslim Congress and had been elected as a Member of Parliament. While this case doesn't directly address tenant rights in lease disputes, it highlights the importance of adherence to constitutional procedures and due process.\n",
      "\n",
      "Case 2 (SC/TAB No. 01A-01F/2017) is a criminal appeal case involving six accused individuals. This case does not pertain to lease agreements or tenant rights.\n",
      "\n",
      "Considering these cases and general principles of law, I can provide the following answer:\n",
      "\n",
      "**Answer:**\n",
      "\n",
      "In Sri Lanka, a tenant in a lease agreement dispute has the right to peaceful possession (quiet enjoyment), repairs and maintenance from the landlord, receive rent payments as agreed upon, and terminate the lease if there's a breach by the landlord. If a tenant is facing issues related to their lease, they can seek mediation or legal recourse through relevant authorities.\n",
      "\n",
      "Please note that this answer may not be exhaustive and might require further clarification based on specific circumstances or local regulations.\n"
     ]
    }
   ],
   "source": [
    "# Print response\n",
    "print(\"ðŸ”· AI Legal Assistant Response:\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”· Top Matching Case Files:\n",
      "ðŸ“„ 012009.pdf\n",
      "ðŸ“„ 01a_01f_2017_tab.pdf\n"
     ]
    }
   ],
   "source": [
    "# Print matched case file names\n",
    "print(\"\\nðŸ”· Top Matching Case Files:\")\n",
    "for case in matched_cases:\n",
    "    print(f\"ðŸ“„ {case['file_name']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
